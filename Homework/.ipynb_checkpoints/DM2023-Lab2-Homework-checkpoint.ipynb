{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: Jason Theodorus\n",
    "\n",
    "Student ID: 109006236\n",
    "\n",
    "GitHub ID: jxsontp\n",
    "\n",
    "Kaggle name: theodorusjasonjet\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the DM2023-Lab2-master. You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/t/09b1d0f3f8584d06848252277cb535f2) regarding Emotion Recognition on Twitter by this link https://www.kaggle.com/t/09b1d0f3f8584d06848252277cb535f2. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "    Submit your last submission __BEFORE the deadline (Dec. 27th 11:59 pm, Wednesday)_. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Dec. 31th 11:59 pm, Sunday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "#get dataset\n",
    "emotions_df = pd.read_csv(\"emotion.csv\")\n",
    "identification_df = pd.read_csv(\"data_identification.csv\")\n",
    "\n",
    "tweetFile = \"tweets_DM.json\"\n",
    "tweetList = []\n",
    "#read json\n",
    "with open(tweetFile,\"r\") as file :\n",
    "    jsonData = file.readlines()\n",
    "\n",
    "# get every line and put into list\n",
    "for line in jsonData :\n",
    "    tweet_data = json.loads(line)\n",
    "    tweetList.append(tweet_data)\n",
    "    \n",
    "tweet_df = pd.DataFrame(tweetList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize\n",
    "#move _score to a temporary and put every data into their corressponding dataset\n",
    "temp_df = tweet_df['_score'].to_frame(name='_score')\n",
    "tweet_df = json_normalize(tweet_df[\"_source\"])\n",
    "tweet_df = tweet_df.rename(columns={\"tweet.tweet_id\": \"tweet_id\"})\n",
    "tweet_df = pd.concat([tweet_df, temp_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have 3 different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet.text</th>\n",
       "      <th>_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          tweet.hashtags  tweet_id   \n",
       "0                             [Snapchat]  0x376b20  \\\n",
       "1          [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "2                           [bibleverse]  0x28b412   \n",
       "3                                     []  0x1cd5b0   \n",
       "4                                     []  0x2de201   \n",
       "...                                  ...       ...   \n",
       "1867530  [mixedfeeling, butimTHATperson]  0x316b80   \n",
       "1867531                               []  0x29d0cb   \n",
       "1867532                               []  0x2a6a4f   \n",
       "1867533                               []  0x24faed   \n",
       "1867534                    [Sundayvibes]  0x34be8c   \n",
       "\n",
       "                                                tweet.text  _score  \n",
       "0        People who post \"add me on #Snapchat\" must be ...     391  \n",
       "1        @brianklaas As we see, Trump is dangerous to #...     433  \n",
       "2        Confident of your obedience, I write to you, k...     232  \n",
       "3                      Now ISSA is stalking Tasha 😂😂😂 <LH>     376  \n",
       "4        \"Trust is not the same as faith. A friend is s...     989  \n",
       "...                                                    ...     ...  \n",
       "1867530  When you buy the last 2 tickets remaining for ...     827  \n",
       "1867531  I swear all this hard work gone pay off one da...     368  \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...     498  \n",
       "1867533  Ah, corporate life, where you can date <LH> us...     840  \n",
       "1867534             Blessed to be living #Sundayvibes <LH>     360  \n",
       "\n",
       "[1867535 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3140b1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x368b73</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x296183</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2bd6e1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2ee1dd</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455558</th>\n",
       "      <td>0x38dba0</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455559</th>\n",
       "      <td>0x300ea2</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455560</th>\n",
       "      <td>0x360b99</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455561</th>\n",
       "      <td>0x22eecf</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455562</th>\n",
       "      <td>0x2fb282</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id       emotion\n",
       "0        0x3140b1       sadness\n",
       "1        0x368b73       disgust\n",
       "2        0x296183  anticipation\n",
       "3        0x2bd6e1           joy\n",
       "4        0x2ee1dd  anticipation\n",
       "...           ...           ...\n",
       "1455558  0x38dba0           joy\n",
       "1455559  0x300ea2           joy\n",
       "1455560  0x360b99          fear\n",
       "1455561  0x22eecf           joy\n",
       "1455562  0x2fb282  anticipation\n",
       "\n",
       "[1455563 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x227e25</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x293813</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x1e1a7e</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x2156a5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x2bb9d2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id identification\n",
       "0        0x28cc61           test\n",
       "1        0x29e452          train\n",
       "2        0x2b3819          train\n",
       "3        0x2db41f           test\n",
       "4        0x2a2acc          train\n",
       "...           ...            ...\n",
       "1867530  0x227e25          train\n",
       "1867531  0x293813          train\n",
       "1867532  0x1e1a7e          train\n",
       "1867533  0x2156a5          train\n",
       "1867534  0x2bb9d2          train\n",
       "\n",
       "[1867535 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identification_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to merge the dataset so its easier to preprocess and do feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "merged_df = pd.merge(tweet_df, identification_df, on='tweet_id', how='outer')\n",
    "merged_df = pd.merge(merged_df, emotions_df, on='tweet_id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet.text</th>\n",
       "      <th>_score</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>391</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>433</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>232</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>376</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>989</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>827</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>368</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>498</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>840</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "      <td>360</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          tweet.hashtags  tweet_id   \n",
       "0                             [Snapchat]  0x376b20  \\\n",
       "1          [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "2                           [bibleverse]  0x28b412   \n",
       "3                                     []  0x1cd5b0   \n",
       "4                                     []  0x2de201   \n",
       "...                                  ...       ...   \n",
       "1867530  [mixedfeeling, butimTHATperson]  0x316b80   \n",
       "1867531                               []  0x29d0cb   \n",
       "1867532                               []  0x2a6a4f   \n",
       "1867533                               []  0x24faed   \n",
       "1867534                    [Sundayvibes]  0x34be8c   \n",
       "\n",
       "                                                tweet.text  _score   \n",
       "0        People who post \"add me on #Snapchat\" must be ...     391  \\\n",
       "1        @brianklaas As we see, Trump is dangerous to #...     433   \n",
       "2        Confident of your obedience, I write to you, k...     232   \n",
       "3                      Now ISSA is stalking Tasha 😂😂😂 <LH>     376   \n",
       "4        \"Trust is not the same as faith. A friend is s...     989   \n",
       "...                                                    ...     ...   \n",
       "1867530  When you buy the last 2 tickets remaining for ...     827   \n",
       "1867531  I swear all this hard work gone pay off one da...     368   \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...     498   \n",
       "1867533  Ah, corporate life, where you can date <LH> us...     840   \n",
       "1867534             Blessed to be living #Sundayvibes <LH>     360   \n",
       "\n",
       "        identification       emotion  \n",
       "0                train  anticipation  \n",
       "1                train       sadness  \n",
       "2                 test           NaN  \n",
       "3                train          fear  \n",
       "4                 test           NaN  \n",
       "...                ...           ...  \n",
       "1867530           test           NaN  \n",
       "1867531           test           NaN  \n",
       "1867532           test           NaN  \n",
       "1867533          train           joy  \n",
       "1867534          train           joy  \n",
       "\n",
       "[1867535 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet.text</th>\n",
       "      <th>_score</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snapchat</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>391</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>freepress TrumpLegacy CNN</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>433</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bibleverse</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>232</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>376</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>989</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>mixedfeeling butimTHATperson</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>827</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td></td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>368</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td></td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>498</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td></td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>840</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>Sundayvibes</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt; Sundayv...</td>\n",
       "      <td>360</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tweet.hashtags  tweet_id   \n",
       "0                            Snapchat  0x376b20  \\\n",
       "1           freepress TrumpLegacy CNN  0x2d5350   \n",
       "2                          bibleverse  0x28b412   \n",
       "3                                      0x1cd5b0   \n",
       "4                                      0x2de201   \n",
       "...                               ...       ...   \n",
       "1867530  mixedfeeling butimTHATperson  0x316b80   \n",
       "1867531                                0x29d0cb   \n",
       "1867532                                0x2a6a4f   \n",
       "1867533                                0x24faed   \n",
       "1867534                   Sundayvibes  0x34be8c   \n",
       "\n",
       "                                                tweet.text  _score   \n",
       "0        People who post \"add me on #Snapchat\" must be ...     391  \\\n",
       "1        @brianklaas As we see, Trump is dangerous to #...     433   \n",
       "2        Confident of your obedience, I write to you, k...     232   \n",
       "3                     Now ISSA is stalking Tasha 😂😂😂 <LH>      376   \n",
       "4        \"Trust is not the same as faith. A friend is s...     989   \n",
       "...                                                    ...     ...   \n",
       "1867530  When you buy the last 2 tickets remaining for ...     827   \n",
       "1867531  I swear all this hard work gone pay off one da...     368   \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...     498   \n",
       "1867533  Ah, corporate life, where you can date <LH> us...     840   \n",
       "1867534  Blessed to be living #Sundayvibes <LH> Sundayv...     360   \n",
       "\n",
       "        identification       emotion  \n",
       "0                train  anticipation  \n",
       "1                train       sadness  \n",
       "2                 test           NaN  \n",
       "3                train          fear  \n",
       "4                 test           NaN  \n",
       "...                ...           ...  \n",
       "1867530           test           NaN  \n",
       "1867531           test           NaN  \n",
       "1867532           test           NaN  \n",
       "1867533          train           joy  \n",
       "1867534          train           joy  \n",
       "\n",
       "[1867535 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change hashtags to string and combine with tweet.text\n",
    "merged_df['tweet.hashtags'] = merged_df['tweet.hashtags'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "#combine hashtags with tweet text into tweet text\n",
    "merged_df['tweet.text'] = merged_df['tweet.text'] + ' ' + merged_df['tweet.hashtags']\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet.text</th>\n",
       "      <th>_score</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snapchat</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>391</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>people who post \"add me on #snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>freepress TrumpLegacy CNN</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>433</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>as we see, trump is dangerous to #freepress ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bibleverse</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>232</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confident of your obedience, i write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>376</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>now issa is stalking tasha 😂😂😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>989</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"trust is not the same as faith. a friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>mixedfeeling butimTHATperson</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>827</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>when you buy the last 2 tickets remaining for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td></td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>368</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i swear all this hard work gone pay off one da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td></td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>498</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no card left when i wasn't in so i have no ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td></td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>840</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>ah, corporate life, where you can date  using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>Sundayvibes</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt; Sundayv...</td>\n",
       "      <td>360</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>blessed to be living #sundayvibes  sundayvibes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tweet.hashtags  tweet_id   \n",
       "0                            Snapchat  0x376b20  \\\n",
       "1           freepress TrumpLegacy CNN  0x2d5350   \n",
       "2                          bibleverse  0x28b412   \n",
       "3                                      0x1cd5b0   \n",
       "4                                      0x2de201   \n",
       "...                               ...       ...   \n",
       "1867530  mixedfeeling butimTHATperson  0x316b80   \n",
       "1867531                                0x29d0cb   \n",
       "1867532                                0x2a6a4f   \n",
       "1867533                                0x24faed   \n",
       "1867534                   Sundayvibes  0x34be8c   \n",
       "\n",
       "                                                tweet.text  _score   \n",
       "0        People who post \"add me on #Snapchat\" must be ...     391  \\\n",
       "1        @brianklaas As we see, Trump is dangerous to #...     433   \n",
       "2        Confident of your obedience, I write to you, k...     232   \n",
       "3                     Now ISSA is stalking Tasha 😂😂😂 <LH>      376   \n",
       "4        \"Trust is not the same as faith. A friend is s...     989   \n",
       "...                                                    ...     ...   \n",
       "1867530  When you buy the last 2 tickets remaining for ...     827   \n",
       "1867531  I swear all this hard work gone pay off one da...     368   \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...     498   \n",
       "1867533  Ah, corporate life, where you can date <LH> us...     840   \n",
       "1867534  Blessed to be living #Sundayvibes <LH> Sundayv...     360   \n",
       "\n",
       "        identification       emotion   \n",
       "0                train  anticipation  \\\n",
       "1                train       sadness   \n",
       "2                 test           NaN   \n",
       "3                train          fear   \n",
       "4                 test           NaN   \n",
       "...                ...           ...   \n",
       "1867530           test           NaN   \n",
       "1867531           test           NaN   \n",
       "1867532           test           NaN   \n",
       "1867533          train           joy   \n",
       "1867534          train           joy   \n",
       "\n",
       "                                                     clean  \n",
       "0        people who post \"add me on #snapchat\" must be ...  \n",
       "1        as we see, trump is dangerous to #freepress ar...  \n",
       "2        confident of your obedience, i write to you, k...  \n",
       "3                         now issa is stalking tasha 😂😂😂    \n",
       "4        \"trust is not the same as faith. a friend is s...  \n",
       "...                                                    ...  \n",
       "1867530  when you buy the last 2 tickets remaining for ...  \n",
       "1867531  i swear all this hard work gone pay off one da...  \n",
       "1867532  no card left when i wasn't in so i have no ide...  \n",
       "1867533  ah, corporate life, where you can date  using ...  \n",
       "1867534     blessed to be living #sundayvibes  sundayvibes  \n",
       "\n",
       "[1867535 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Cleaning\n",
    "\n",
    "#Remove Mentions (@xxxxx)\n",
    "merged_df[\"clean\"] = merged_df[\"tweet.text\"].str.replace('@[A-Za-z0-9]+\\s?', '', regex=True)\n",
    "\n",
    "#Remove <LH>\n",
    "merged_df['clean'] = merged_df['clean'].str.replace('<LH>', '', regex=False)\n",
    "\n",
    "#Convert all to lowercase\n",
    "merged_df['clean'] = merged_df['clean'].str.lower()\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        emotion      _score\n",
      "0         anger  512.108109\n",
      "1  anticipation  511.650254\n",
      "2       disgust  512.740922\n",
      "3          fear  512.792622\n",
      "4           joy  512.856237\n",
      "5       sadness  511.608989\n",
      "6      surprise  512.039586\n",
      "7         trust  512.523073\n",
      "        emotion     count        mean         std  min    25%    50%    75%   \n",
      "0         anger   39867.0  512.108109  296.465849  1.0  256.0  511.0  769.0  \\\n",
      "1  anticipation  248935.0  511.650254  295.267569  1.0  256.0  511.0  767.0   \n",
      "2       disgust  139101.0  512.740922  295.369060  1.0  257.0  512.0  769.0   \n",
      "3          fear   63999.0  512.792622  295.902792  1.0  255.0  514.0  769.0   \n",
      "4           joy  516017.0  512.856237  295.805142  1.0  256.0  513.0  769.0   \n",
      "5       sadness  193437.0  511.608989  295.639968  1.0  256.0  510.0  768.0   \n",
      "6      surprise   48729.0  512.039586  295.817604  1.0  253.0  513.0  767.0   \n",
      "7         trust  205478.0  512.523073  295.616933  1.0  256.0  513.0  768.0   \n",
      "\n",
      "      max  \n",
      "0  1024.0  \n",
      "1  1024.0  \n",
      "2  1024.0  \n",
      "3  1024.0  \n",
      "4  1024.0  \n",
      "5  1024.0  \n",
      "6  1024.0  \n",
      "7  1024.0  \n"
     ]
    }
   ],
   "source": [
    "# if we take the mean of each score they are similar\n",
    "average_scores = merged_df.groupby('emotion')['_score'].mean().reset_index()\n",
    "print(average_scores)\n",
    "score_stats = merged_df.groupby('emotion')['_score'].describe().reset_index()\n",
    "print(score_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5          120\n",
       "7          481\n",
       "11         839\n",
       "13         887\n",
       "17         668\n",
       "          ... \n",
       "1867526     94\n",
       "1867527    627\n",
       "1867528    274\n",
       "1867533    840\n",
       "1867534    360\n",
       "Name: _score, Length: 516017, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if we take an example from joy here are the scores\n",
    "joy_scores = merged_df[merged_df['emotion'] == 'joy']['_score']\n",
    "\n",
    "joy_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the 2 texts below i can assume that the higher the score the more unsure the dataset is predicting the correct sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm SO HAPPY!!! #NoWonder the name of this show! #Happy! @HappySYFY @SYFY @Chris_Meloni 👏👏👏👏👏 NoWonder Happy\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text with score 0-100\n",
    "merged_df[\"tweet.text\"][1867526]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I love suffering 🙃🙃 I love when valium does nothing to help 🙃🙃 I love when my doctors say that they've done all they can 🙃🙃 <LH> \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text with score 900+\n",
    "merged_df[\"tweet.text\"][11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So maybe by ranking them we can get a correlation of the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet.text</th>\n",
       "      <th>_score</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean</th>\n",
       "      <th>score_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snapchat</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>391</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>people who post \"add me on #snapchat\" must be ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>freepress TrumpLegacy CNN</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>433</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>as we see, trump is dangerous to #freepress ar...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bibleverse</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>232</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confident of your obedience, i write to you, k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>376</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>now issa is stalking tasha 😂😂😂</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>989</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"trust is not the same as faith. a friend is s...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>mixedfeeling butimTHATperson</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>827</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>when you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td></td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>368</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i swear all this hard work gone pay off one da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td></td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>498</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no card left when i wasn't in so i have no ide...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td></td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>840</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>ah, corporate life, where you can date  using ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>Sundayvibes</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt; Sundayv...</td>\n",
       "      <td>360</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>blessed to be living #sundayvibes  sundayvibes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tweet.hashtags  tweet_id   \n",
       "0                            Snapchat  0x376b20  \\\n",
       "1           freepress TrumpLegacy CNN  0x2d5350   \n",
       "2                          bibleverse  0x28b412   \n",
       "3                                      0x1cd5b0   \n",
       "4                                      0x2de201   \n",
       "...                               ...       ...   \n",
       "1867530  mixedfeeling butimTHATperson  0x316b80   \n",
       "1867531                                0x29d0cb   \n",
       "1867532                                0x2a6a4f   \n",
       "1867533                                0x24faed   \n",
       "1867534                   Sundayvibes  0x34be8c   \n",
       "\n",
       "                                                tweet.text  _score   \n",
       "0        People who post \"add me on #Snapchat\" must be ...     391  \\\n",
       "1        @brianklaas As we see, Trump is dangerous to #...     433   \n",
       "2        Confident of your obedience, I write to you, k...     232   \n",
       "3                     Now ISSA is stalking Tasha 😂😂😂 <LH>      376   \n",
       "4        \"Trust is not the same as faith. A friend is s...     989   \n",
       "...                                                    ...     ...   \n",
       "1867530  When you buy the last 2 tickets remaining for ...     827   \n",
       "1867531  I swear all this hard work gone pay off one da...     368   \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...     498   \n",
       "1867533  Ah, corporate life, where you can date <LH> us...     840   \n",
       "1867534  Blessed to be living #Sundayvibes <LH> Sundayv...     360   \n",
       "\n",
       "        identification       emotion   \n",
       "0                train  anticipation  \\\n",
       "1                train       sadness   \n",
       "2                 test           NaN   \n",
       "3                train          fear   \n",
       "4                 test           NaN   \n",
       "...                ...           ...   \n",
       "1867530           test           NaN   \n",
       "1867531           test           NaN   \n",
       "1867532           test           NaN   \n",
       "1867533          train           joy   \n",
       "1867534          train           joy   \n",
       "\n",
       "                                                     clean  score_category  \n",
       "0        people who post \"add me on #snapchat\" must be ...               1  \n",
       "1        as we see, trump is dangerous to #freepress ar...               3  \n",
       "2        confident of your obedience, i write to you, k...               1  \n",
       "3                         now issa is stalking tasha 😂😂😂                 1  \n",
       "4        \"trust is not the same as faith. a friend is s...               5  \n",
       "...                                                    ...             ...  \n",
       "1867530  when you buy the last 2 tickets remaining for ...               5  \n",
       "1867531  i swear all this hard work gone pay off one da...               1  \n",
       "1867532  no card left when i wasn't in so i have no ide...               3  \n",
       "1867533  ah, corporate life, where you can date  using ...               5  \n",
       "1867534     blessed to be living #sundayvibes  sundayvibes               1  \n",
       "\n",
       "[1867535 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Binning\n",
    "bins = [0, 200,400, 600, 800,1000, float('inf')]\n",
    "labels = ['very low','low', 'medium', 'high', 'very_high', \"max\"]\n",
    "\n",
    "# Bin the scores\n",
    "merged_df['score_category'] = pd.cut(merged_df['_score'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "#then apply label-encoding on these binning\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "merged_df['score_category'] = label_encoder.fit_transform(merged_df['score_category'])\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean</th>\n",
       "      <th>score_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>391</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>people who post \"add me on #snapchat\" must be ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>433</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>as we see, trump is dangerous to #freepress ar...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>232</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confident of your obedience, i write to you, k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>376</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>now issa is stalking tasha 😂😂😂</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>989</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"trust is not the same as faith. a friend is s...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>827</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>when you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>368</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i swear all this hard work gone pay off one da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>498</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no card left when i wasn't in so i have no ide...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x24faed</td>\n",
       "      <td>840</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>ah, corporate life, where you can date  using ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>360</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>blessed to be living #sundayvibes  sundayvibes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id  _score identification       emotion   \n",
       "0        0x376b20     391          train  anticipation  \\\n",
       "1        0x2d5350     433          train       sadness   \n",
       "2        0x28b412     232           test           NaN   \n",
       "3        0x1cd5b0     376          train          fear   \n",
       "4        0x2de201     989           test           NaN   \n",
       "...           ...     ...            ...           ...   \n",
       "1867530  0x316b80     827           test           NaN   \n",
       "1867531  0x29d0cb     368           test           NaN   \n",
       "1867532  0x2a6a4f     498           test           NaN   \n",
       "1867533  0x24faed     840          train           joy   \n",
       "1867534  0x34be8c     360          train           joy   \n",
       "\n",
       "                                                     clean  score_category  \n",
       "0        people who post \"add me on #snapchat\" must be ...               1  \n",
       "1        as we see, trump is dangerous to #freepress ar...               3  \n",
       "2        confident of your obedience, i write to you, k...               1  \n",
       "3                         now issa is stalking tasha 😂😂😂                 1  \n",
       "4        \"trust is not the same as faith. a friend is s...               5  \n",
       "...                                                    ...             ...  \n",
       "1867530  when you buy the last 2 tickets remaining for ...               5  \n",
       "1867531  i swear all this hard work gone pay off one da...               1  \n",
       "1867532  no card left when i wasn't in so i have no ide...               3  \n",
       "1867533  ah, corporate life, where you can date  using ...               5  \n",
       "1867534     blessed to be living #sundayvibes  sundayvibes               1  \n",
       "\n",
       "[1867535 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the no longer used columns\n",
    "dropcolumns = [\"tweet.hashtags\",\"tweet.text\"]\n",
    "merged_df.drop(columns=dropcolumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1455563\n",
      "411972\n"
     ]
    }
   ],
   "source": [
    "#split to train and test\n",
    "train_count = merged_df[merged_df['identification'] == 'train'].shape[0]\n",
    "test_count = merged_df[merged_df['identification'] == 'test'].shape[0]\n",
    "print(train_count)\n",
    "print(test_count)\n",
    "train_df = merged_df[merged_df['identification'] == 'train']\n",
    "test_df = merged_df[merged_df['identification'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet.text</th>\n",
       "      <th>_score</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean</th>\n",
       "      <th>score_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snapchat</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>391</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>people who post \"add me on #snapchat\" must be ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>freepress TrumpLegacy CNN</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>433</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>as we see, trump is dangerous to #freepress ar...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>376</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>now issa is stalking tasha 😂😂😂</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>authentic LaughOutLoud</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>120</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>thx for the best time tonight. what stories! h...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>1021</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>still waiting on those supplies liscus.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867526</th>\n",
       "      <td>NoWonder Happy</td>\n",
       "      <td>0x321566</td>\n",
       "      <td>I'm SO HAPPY!!! #NoWonder the name of this sho...</td>\n",
       "      <td>94</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>i'm so happy!!! #nowonder the name of this sho...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867527</th>\n",
       "      <td></td>\n",
       "      <td>0x38959e</td>\n",
       "      <td>In every circumtance I'd like to be thankful t...</td>\n",
       "      <td>627</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>in every circumtance i'd like to be thankful t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867528</th>\n",
       "      <td>blessyou</td>\n",
       "      <td>0x2cbca6</td>\n",
       "      <td>there's currently two girls walking around the...</td>\n",
       "      <td>274</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>there's currently two girls walking around the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td></td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>840</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>ah, corporate life, where you can date  using ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>Sundayvibes</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt; Sundayv...</td>\n",
       "      <td>360</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>blessed to be living #sundayvibes  sundayvibes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet.hashtags  tweet_id   \n",
       "0                         Snapchat  0x376b20  \\\n",
       "1        freepress TrumpLegacy CNN  0x2d5350   \n",
       "3                                   0x1cd5b0   \n",
       "5           authentic LaughOutLoud  0x1d755c   \n",
       "6                                   0x2c91a8   \n",
       "...                            ...       ...   \n",
       "1867526             NoWonder Happy  0x321566   \n",
       "1867527                             0x38959e   \n",
       "1867528                   blessyou  0x2cbca6   \n",
       "1867533                             0x24faed   \n",
       "1867534                Sundayvibes  0x34be8c   \n",
       "\n",
       "                                                tweet.text  _score   \n",
       "0        People who post \"add me on #Snapchat\" must be ...     391  \\\n",
       "1        @brianklaas As we see, Trump is dangerous to #...     433   \n",
       "3                     Now ISSA is stalking Tasha 😂😂😂 <LH>      376   \n",
       "5        @RISKshow @TheKevinAllison Thx for the BEST TI...     120   \n",
       "6            Still waiting on those supplies Liscus. <LH>     1021   \n",
       "...                                                    ...     ...   \n",
       "1867526  I'm SO HAPPY!!! #NoWonder the name of this sho...      94   \n",
       "1867527  In every circumtance I'd like to be thankful t...     627   \n",
       "1867528  there's currently two girls walking around the...     274   \n",
       "1867533  Ah, corporate life, where you can date <LH> us...     840   \n",
       "1867534  Blessed to be living #Sundayvibes <LH> Sundayv...     360   \n",
       "\n",
       "        identification       emotion   \n",
       "0                train  anticipation  \\\n",
       "1                train       sadness   \n",
       "3                train          fear   \n",
       "5                train           joy   \n",
       "6                train  anticipation   \n",
       "...                ...           ...   \n",
       "1867526          train           joy   \n",
       "1867527          train           joy   \n",
       "1867528          train           joy   \n",
       "1867533          train           joy   \n",
       "1867534          train           joy   \n",
       "\n",
       "                                                     clean  score_category  \n",
       "0        people who post \"add me on #snapchat\" must be ...               1  \n",
       "1        as we see, trump is dangerous to #freepress ar...               3  \n",
       "3                         now issa is stalking tasha 😂😂😂                 1  \n",
       "5        thx for the best time tonight. what stories! h...               4  \n",
       "6                still waiting on those supplies liscus.                 2  \n",
       "...                                                    ...             ...  \n",
       "1867526  i'm so happy!!! #nowonder the name of this sho...               4  \n",
       "1867527  in every circumtance i'd like to be thankful t...               0  \n",
       "1867528  there's currently two girls walking around the...               1  \n",
       "1867533  ah, corporate life, where you can date  using ...               5  \n",
       "1867534     blessed to be living #sundayvibes  sundayvibes               1  \n",
       "\n",
       "[1455563 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# get numerical features of text using TF-IDF\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize, stop_words='english')\n",
    "\n",
    "# Train data\n",
    "X_text_train = train_df['clean'].astype(str) #confirm its string so tfidf can process\n",
    "X_score_category_train = train_df['score_category'].astype(int)  # convert to int for vectorization\n",
    "X_score_train = train_df['_score'].astype(float)  # Convert to float for vectorization\n",
    "\n",
    "X_train_text_tfidf = tfidf_vectorizer.fit_transform(X_text_train)\n",
    "X_train_text_tfidf = scipy.sparse.csr_matrix(X_train_text_tfidf)  \n",
    "\n",
    "# Test data\n",
    "X_text_test = test_df['clean'].astype(str) # confirm its string so tfidf can process\n",
    "X_score_category_test = test_df['score_category'].astype(int)  # convert to int for vectorization\n",
    "X_score_test = test_df['_score'].astype(float)  # convert to float for vectorization\n",
    "\n",
    "X_test_text_tfidf = tfidf_vectorizer.transform(X_text_test)\n",
    "X_test_text_tfidf = scipy.sparse.csr_matrix(X_test_text_tfidf)\n",
    "\n",
    "# stack matrices so the features can be combined\n",
    "# but the features i engineered are dominated by the TFIDF matrix, because the TFIDF Matrix is very large, so i don't think\n",
    "# the feature engineering is that useful.\n",
    "X_train = scipy.sparse.hstack([X_train_text_tfidf, scipy.sparse.csr_matrix(X_score_category_train).reshape(-1, 1), scipy.sparse.csr_matrix(X_score_train).reshape(-1, 1)])\n",
    "X_test = scipy.sparse.hstack([X_test_text_tfidf, scipy.sparse.csr_matrix(X_score_category_test).reshape(-1, 1), scipy.sparse.csr_matrix(X_score_test).reshape(-1, 1)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1455563x710277 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13170004 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1455563x710279 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15796394 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<411972x710279 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4799020 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet.text</th>\n",
       "      <th>_score</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean</th>\n",
       "      <th>score_category</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>word2vec_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snapchat</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>391</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>people who post \"add me on #snapchat\" must be ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[people, who, post, ``, add, me, on, #, snapch...</td>\n",
       "      <td>[people, who, post, , add, me, on, , snapchat,...</td>\n",
       "      <td>[[-1.3463544, -0.71223205, 6.3136954, -1.19067...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>freepress TrumpLegacy CNN</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>433</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>as we see, trump is dangerous to #freepress ar...</td>\n",
       "      <td>3</td>\n",
       "      <td>[as, we, see, ,, trump, is, dangerous, to, #, ...</td>\n",
       "      <td>[as, we, see, , trump, is, dangerous, to, , fr...</td>\n",
       "      <td>[[-1.0479634, -0.5431899, 1.1762719, -0.100929...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bibleverse</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>232</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confident of your obedience, i write to you, k...</td>\n",
       "      <td>1</td>\n",
       "      <td>[confident, of, your, obedience, ,, i, write, ...</td>\n",
       "      <td>[confident, of, your, obedience, , i, write, t...</td>\n",
       "      <td>[[-1.217517, -0.78689027, 1.6523653, 1.0162727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>376</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>now issa is stalking tasha 😂😂😂</td>\n",
       "      <td>1</td>\n",
       "      <td>[now, issa, is, stalking, tasha, 😂😂😂]</td>\n",
       "      <td>[now, issa, is, stalking, tasha, ]</td>\n",
       "      <td>[[-2.1855633, 2.2293904, 5.1015863, -0.5360209...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>989</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"trust is not the same as faith. a friend is s...</td>\n",
       "      <td>5</td>\n",
       "      <td>[``, trust, is, not, the, same, as, faith, ., ...</td>\n",
       "      <td>[, trust, is, not, the, same, as, faith, , a, ...</td>\n",
       "      <td>[[-2.8595655, 1.1429472, 7.9727573, -4.1696177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>mixedfeeling butimTHATperson</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>827</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>when you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[when, you, buy, the, last, 2, tickets, remain...</td>\n",
       "      <td>[when, you, buy, the, last, 2, tickets, remain...</td>\n",
       "      <td>[[-1.5189266, 0.9107626, 5.598923, -0.38799408...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td></td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>368</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i swear all this hard work gone pay off one da...</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, swear, all, this, hard, work, gone, pay, o...</td>\n",
       "      <td>[i, swear, all, this, hard, work, gone, pay, o...</td>\n",
       "      <td>[[0.120105036, 3.1113946, 3.276737, 0.16804332...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td></td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>498</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no card left when i wasn't in so i have no ide...</td>\n",
       "      <td>3</td>\n",
       "      <td>[no, card, left, when, i, was, n't, in, so, i,...</td>\n",
       "      <td>[no, card, left, when, i, was, nt, in, so, i, ...</td>\n",
       "      <td>[[-2.8704882, -0.10452109, 2.0424407, -3.47849...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td></td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>840</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>ah, corporate life, where you can date  using ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ah, ,, corporate, life, ,, where, you, can, d...</td>\n",
       "      <td>[ah, , corporate, life, , where, you, can, dat...</td>\n",
       "      <td>[[-0.71798134, 0.44436654, -0.46484193, -0.536...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>Sundayvibes</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt; Sundayv...</td>\n",
       "      <td>360</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>blessed to be living #sundayvibes  sundayvibes</td>\n",
       "      <td>1</td>\n",
       "      <td>[blessed, to, be, living, #, sundayvibes, sund...</td>\n",
       "      <td>[blessed, to, be, living, , sundayvibes, sunda...</td>\n",
       "      <td>[[1.4343666, 1.4452337, -0.2801961, 1.1160922,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tweet.hashtags  tweet_id   \n",
       "0                            Snapchat  0x376b20  \\\n",
       "1           freepress TrumpLegacy CNN  0x2d5350   \n",
       "2                          bibleverse  0x28b412   \n",
       "3                                      0x1cd5b0   \n",
       "4                                      0x2de201   \n",
       "...                               ...       ...   \n",
       "1867530  mixedfeeling butimTHATperson  0x316b80   \n",
       "1867531                                0x29d0cb   \n",
       "1867532                                0x2a6a4f   \n",
       "1867533                                0x24faed   \n",
       "1867534                   Sundayvibes  0x34be8c   \n",
       "\n",
       "                                                tweet.text  _score   \n",
       "0        People who post \"add me on #Snapchat\" must be ...     391  \\\n",
       "1        @brianklaas As we see, Trump is dangerous to #...     433   \n",
       "2        Confident of your obedience, I write to you, k...     232   \n",
       "3                     Now ISSA is stalking Tasha 😂😂😂 <LH>      376   \n",
       "4        \"Trust is not the same as faith. A friend is s...     989   \n",
       "...                                                    ...     ...   \n",
       "1867530  When you buy the last 2 tickets remaining for ...     827   \n",
       "1867531  I swear all this hard work gone pay off one da...     368   \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...     498   \n",
       "1867533  Ah, corporate life, where you can date <LH> us...     840   \n",
       "1867534  Blessed to be living #Sundayvibes <LH> Sundayv...     360   \n",
       "\n",
       "        identification       emotion   \n",
       "0                train  anticipation  \\\n",
       "1                train       sadness   \n",
       "2                 test           NaN   \n",
       "3                train          fear   \n",
       "4                 test           NaN   \n",
       "...                ...           ...   \n",
       "1867530           test           NaN   \n",
       "1867531           test           NaN   \n",
       "1867532           test           NaN   \n",
       "1867533          train           joy   \n",
       "1867534          train           joy   \n",
       "\n",
       "                                                     clean  score_category   \n",
       "0        people who post \"add me on #snapchat\" must be ...               1  \\\n",
       "1        as we see, trump is dangerous to #freepress ar...               3   \n",
       "2        confident of your obedience, i write to you, k...               1   \n",
       "3                         now issa is stalking tasha 😂😂😂                 1   \n",
       "4        \"trust is not the same as faith. a friend is s...               5   \n",
       "...                                                    ...             ...   \n",
       "1867530  when you buy the last 2 tickets remaining for ...               5   \n",
       "1867531  i swear all this hard work gone pay off one da...               1   \n",
       "1867532  no card left when i wasn't in so i have no ide...               3   \n",
       "1867533  ah, corporate life, where you can date  using ...               5   \n",
       "1867534     blessed to be living #sundayvibes  sundayvibes               1   \n",
       "\n",
       "                                            tokenized_text   \n",
       "0        [people, who, post, ``, add, me, on, #, snapch...  \\\n",
       "1        [as, we, see, ,, trump, is, dangerous, to, #, ...   \n",
       "2        [confident, of, your, obedience, ,, i, write, ...   \n",
       "3                    [now, issa, is, stalking, tasha, 😂😂😂]   \n",
       "4        [``, trust, is, not, the, same, as, faith, ., ...   \n",
       "...                                                    ...   \n",
       "1867530  [when, you, buy, the, last, 2, tickets, remain...   \n",
       "1867531  [i, swear, all, this, hard, work, gone, pay, o...   \n",
       "1867532  [no, card, left, when, i, was, n't, in, so, i,...   \n",
       "1867533  [ah, ,, corporate, life, ,, where, you, can, d...   \n",
       "1867534  [blessed, to, be, living, #, sundayvibes, sund...   \n",
       "\n",
       "                                              clean_tokens   \n",
       "0        [people, who, post, , add, me, on, , snapchat,...  \\\n",
       "1        [as, we, see, , trump, is, dangerous, to, , fr...   \n",
       "2        [confident, of, your, obedience, , i, write, t...   \n",
       "3                       [now, issa, is, stalking, tasha, ]   \n",
       "4        [, trust, is, not, the, same, as, faith, , a, ...   \n",
       "...                                                    ...   \n",
       "1867530  [when, you, buy, the, last, 2, tickets, remain...   \n",
       "1867531  [i, swear, all, this, hard, work, gone, pay, o...   \n",
       "1867532  [no, card, left, when, i, was, nt, in, so, i, ...   \n",
       "1867533  [ah, , corporate, life, , where, you, can, dat...   \n",
       "1867534  [blessed, to, be, living, , sundayvibes, sunda...   \n",
       "\n",
       "                                       word2vec_embeddings  \n",
       "0        [[-1.3463544, -0.71223205, 6.3136954, -1.19067...  \n",
       "1        [[-1.0479634, -0.5431899, 1.1762719, -0.100929...  \n",
       "2        [[-1.217517, -0.78689027, 1.6523653, 1.0162727...  \n",
       "3        [[-2.1855633, 2.2293904, 5.1015863, -0.5360209...  \n",
       "4        [[-2.8595655, 1.1429472, 7.9727573, -4.1696177...  \n",
       "...                                                    ...  \n",
       "1867530  [[-1.5189266, 0.9107626, 5.598923, -0.38799408...  \n",
       "1867531  [[0.120105036, 3.1113946, 3.276737, 0.16804332...  \n",
       "1867532  [[-2.8704882, -0.10452109, 2.0424407, -3.47849...  \n",
       "1867533  [[-0.71798134, 0.44436654, -0.46484193, -0.536...  \n",
       "1867534  [[1.4343666, 1.4452337, -0.2801961, 1.1160922,...  \n",
       "\n",
       "[1867535 rows x 11 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#tokenize the clean column\n",
    "merged_df['tokenized_text'] = merged_df['clean'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove special characters\n",
    "import re\n",
    "merged_df['clean_tokens'] = merged_df['tokenized_text'].apply(lambda tokens: [re.sub(r'[^a-zA-Z0-9]', '', token) for token in tokens if token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec embeddings\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences=merged_df['tokenized_text'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "merged_df['word2vec_embeddings'] = merged_df['tokenized_text'].apply(lambda x: [model.wv[word] for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet.text</th>\n",
       "      <th>_score</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean</th>\n",
       "      <th>score_category</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>word2vec_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snapchat</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>391</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>people who post \"add me on #snapchat\" must be ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[people, who, post, ``, add, me, on, #, snapch...</td>\n",
       "      <td>[people, who, post, , add, me, on, , snapchat,...</td>\n",
       "      <td>[[-1.3463544, -0.71223205, 6.3136954, -1.19067...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>freepress TrumpLegacy CNN</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>433</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>as we see, trump is dangerous to #freepress ar...</td>\n",
       "      <td>3</td>\n",
       "      <td>[as, we, see, ,, trump, is, dangerous, to, #, ...</td>\n",
       "      <td>[as, we, see, , trump, is, dangerous, to, , fr...</td>\n",
       "      <td>[[-1.0479634, -0.5431899, 1.1762719, -0.100929...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bibleverse</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>232</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confident of your obedience, i write to you, k...</td>\n",
       "      <td>1</td>\n",
       "      <td>[confident, of, your, obedience, ,, i, write, ...</td>\n",
       "      <td>[confident, of, your, obedience, , i, write, t...</td>\n",
       "      <td>[[-1.217517, -0.78689027, 1.6523653, 1.0162727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>376</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>now issa is stalking tasha 😂😂😂</td>\n",
       "      <td>1</td>\n",
       "      <td>[now, issa, is, stalking, tasha, 😂😂😂]</td>\n",
       "      <td>[now, issa, is, stalking, tasha, ]</td>\n",
       "      <td>[[-2.1855633, 2.2293904, 5.1015863, -0.5360209...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>989</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"trust is not the same as faith. a friend is s...</td>\n",
       "      <td>5</td>\n",
       "      <td>[``, trust, is, not, the, same, as, faith, ., ...</td>\n",
       "      <td>[, trust, is, not, the, same, as, faith, , a, ...</td>\n",
       "      <td>[[-2.8595655, 1.1429472, 7.9727573, -4.1696177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>mixedfeeling butimTHATperson</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>827</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>when you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[when, you, buy, the, last, 2, tickets, remain...</td>\n",
       "      <td>[when, you, buy, the, last, 2, tickets, remain...</td>\n",
       "      <td>[[-1.5189266, 0.9107626, 5.598923, -0.38799408...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td></td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>368</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i swear all this hard work gone pay off one da...</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, swear, all, this, hard, work, gone, pay, o...</td>\n",
       "      <td>[i, swear, all, this, hard, work, gone, pay, o...</td>\n",
       "      <td>[[0.120105036, 3.1113946, 3.276737, 0.16804332...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td></td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>498</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no card left when i wasn't in so i have no ide...</td>\n",
       "      <td>3</td>\n",
       "      <td>[no, card, left, when, i, was, n't, in, so, i,...</td>\n",
       "      <td>[no, card, left, when, i, was, nt, in, so, i, ...</td>\n",
       "      <td>[[-2.8704882, -0.10452109, 2.0424407, -3.47849...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td></td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>840</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>ah, corporate life, where you can date  using ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ah, ,, corporate, life, ,, where, you, can, d...</td>\n",
       "      <td>[ah, , corporate, life, , where, you, can, dat...</td>\n",
       "      <td>[[-0.71798134, 0.44436654, -0.46484193, -0.536...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>Sundayvibes</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt; Sundayv...</td>\n",
       "      <td>360</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>blessed to be living #sundayvibes  sundayvibes</td>\n",
       "      <td>1</td>\n",
       "      <td>[blessed, to, be, living, #, sundayvibes, sund...</td>\n",
       "      <td>[blessed, to, be, living, , sundayvibes, sunda...</td>\n",
       "      <td>[[1.4343666, 1.4452337, -0.2801961, 1.1160922,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tweet.hashtags  tweet_id   \n",
       "0                            Snapchat  0x376b20  \\\n",
       "1           freepress TrumpLegacy CNN  0x2d5350   \n",
       "2                          bibleverse  0x28b412   \n",
       "3                                      0x1cd5b0   \n",
       "4                                      0x2de201   \n",
       "...                               ...       ...   \n",
       "1867530  mixedfeeling butimTHATperson  0x316b80   \n",
       "1867531                                0x29d0cb   \n",
       "1867532                                0x2a6a4f   \n",
       "1867533                                0x24faed   \n",
       "1867534                   Sundayvibes  0x34be8c   \n",
       "\n",
       "                                                tweet.text  _score   \n",
       "0        People who post \"add me on #Snapchat\" must be ...     391  \\\n",
       "1        @brianklaas As we see, Trump is dangerous to #...     433   \n",
       "2        Confident of your obedience, I write to you, k...     232   \n",
       "3                     Now ISSA is stalking Tasha 😂😂😂 <LH>      376   \n",
       "4        \"Trust is not the same as faith. A friend is s...     989   \n",
       "...                                                    ...     ...   \n",
       "1867530  When you buy the last 2 tickets remaining for ...     827   \n",
       "1867531  I swear all this hard work gone pay off one da...     368   \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...     498   \n",
       "1867533  Ah, corporate life, where you can date <LH> us...     840   \n",
       "1867534  Blessed to be living #Sundayvibes <LH> Sundayv...     360   \n",
       "\n",
       "        identification       emotion   \n",
       "0                train  anticipation  \\\n",
       "1                train       sadness   \n",
       "2                 test           NaN   \n",
       "3                train          fear   \n",
       "4                 test           NaN   \n",
       "...                ...           ...   \n",
       "1867530           test           NaN   \n",
       "1867531           test           NaN   \n",
       "1867532           test           NaN   \n",
       "1867533          train           joy   \n",
       "1867534          train           joy   \n",
       "\n",
       "                                                     clean  score_category   \n",
       "0        people who post \"add me on #snapchat\" must be ...               1  \\\n",
       "1        as we see, trump is dangerous to #freepress ar...               3   \n",
       "2        confident of your obedience, i write to you, k...               1   \n",
       "3                         now issa is stalking tasha 😂😂😂                 1   \n",
       "4        \"trust is not the same as faith. a friend is s...               5   \n",
       "...                                                    ...             ...   \n",
       "1867530  when you buy the last 2 tickets remaining for ...               5   \n",
       "1867531  i swear all this hard work gone pay off one da...               1   \n",
       "1867532  no card left when i wasn't in so i have no ide...               3   \n",
       "1867533  ah, corporate life, where you can date  using ...               5   \n",
       "1867534     blessed to be living #sundayvibes  sundayvibes               1   \n",
       "\n",
       "                                            tokenized_text   \n",
       "0        [people, who, post, ``, add, me, on, #, snapch...  \\\n",
       "1        [as, we, see, ,, trump, is, dangerous, to, #, ...   \n",
       "2        [confident, of, your, obedience, ,, i, write, ...   \n",
       "3                    [now, issa, is, stalking, tasha, 😂😂😂]   \n",
       "4        [``, trust, is, not, the, same, as, faith, ., ...   \n",
       "...                                                    ...   \n",
       "1867530  [when, you, buy, the, last, 2, tickets, remain...   \n",
       "1867531  [i, swear, all, this, hard, work, gone, pay, o...   \n",
       "1867532  [no, card, left, when, i, was, n't, in, so, i,...   \n",
       "1867533  [ah, ,, corporate, life, ,, where, you, can, d...   \n",
       "1867534  [blessed, to, be, living, #, sundayvibes, sund...   \n",
       "\n",
       "                                              clean_tokens   \n",
       "0        [people, who, post, , add, me, on, , snapchat,...  \\\n",
       "1        [as, we, see, , trump, is, dangerous, to, , fr...   \n",
       "2        [confident, of, your, obedience, , i, write, t...   \n",
       "3                       [now, issa, is, stalking, tasha, ]   \n",
       "4        [, trust, is, not, the, same, as, faith, , a, ...   \n",
       "...                                                    ...   \n",
       "1867530  [when, you, buy, the, last, 2, tickets, remain...   \n",
       "1867531  [i, swear, all, this, hard, work, gone, pay, o...   \n",
       "1867532  [no, card, left, when, i, was, nt, in, so, i, ...   \n",
       "1867533  [ah, , corporate, life, , where, you, can, dat...   \n",
       "1867534  [blessed, to, be, living, , sundayvibes, sunda...   \n",
       "\n",
       "                                       word2vec_embeddings  \n",
       "0        [[-1.3463544, -0.71223205, 6.3136954, -1.19067...  \n",
       "1        [[-1.0479634, -0.5431899, 1.1762719, -0.100929...  \n",
       "2        [[-1.217517, -0.78689027, 1.6523653, 1.0162727...  \n",
       "3        [[-2.1855633, 2.2293904, 5.1015863, -0.5360209...  \n",
       "4        [[-2.8595655, 1.1429472, 7.9727573, -4.1696177...  \n",
       "...                                                    ...  \n",
       "1867530  [[-1.5189266, 0.9107626, 5.598923, -0.38799408...  \n",
       "1867531  [[0.120105036, 3.1113946, 3.276737, 0.16804332...  \n",
       "1867532  [[-2.8704882, -0.10452109, 2.0424407, -3.47849...  \n",
       "1867533  [[-0.71798134, 0.44436654, -0.46484193, -0.536...  \n",
       "1867534  [[1.4343666, 1.4452337, -0.2801961, 1.1160922,...  \n",
       "\n",
       "[1867535 rows x 11 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1455563\n",
      "411972\n"
     ]
    }
   ],
   "source": [
    "train_count = merged_df[merged_df['identification'] == 'train'].shape[0]\n",
    "test_count = merged_df[merged_df['identification'] == 'test'].shape[0]\n",
    "print(train_count)\n",
    "print(test_count)\n",
    "train_df = merged_df[merged_df['identification'] == 'train']\n",
    "test_df = merged_df[merged_df['identification'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[[\"_score\",\"score_category\",\"flattened_embeddings\"]]\n",
    "X_test = train_df[[\"_score\",\"score_category\",\"flattened_embeddings\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_embedding_size = max(len(embedding) for embedding in df['flattened_embeddings'])\n",
    "\n",
    "embeddings_df = pd.DataFrame(df['flattened_embeddings'].tolist(), columns=[f'embedding_{i}' for i in range(max_embedding_size)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_df['emotion'])\n",
    "\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=1000,\n",
    "    max_depth=10,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='multi:softmax',  #multi:softmax for multiclass classification\n",
    "    num_class=len(le.classes_),  # number of classes\n",
    "    random_state=42)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yPred = le.inverse_transform(model.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for XGBoost, i experimented with many different parameters especially for multiclass classification because the prediction consist of many emotions (8). But, i still think that the default parameters are still the optimal working ones, because they provide the best score out of the parameters i tried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Select features for testing\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Model predictionx\u001b[39;00m\n\u001b[0;32m     22\u001b[0m yPred \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39minverse_transform(model\u001b[38;5;241m.\u001b[39mpredict(X_test))\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43maccuracy\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_df['emotion'])\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yPred = le.inverse_transform(model.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for RFC I've also tested many different parameters,but it doesn't work as well as XGBoost. In my opinion, it could be because the nature of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now save the predictions to csv\n",
    "temp = pd.DataFrame({'id': test_df['tweet_id'], 'emotion': yPred})\n",
    "temp.to_csv('predictions6.csv', index=False)\n",
    "# with this csv file i can upload my predictions to the kaggle website"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
